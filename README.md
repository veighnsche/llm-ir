# LLM-IR â€” A Token-Cheap Programming Language for LLMs

LLM-IR is a programming language that **isnâ€™t designed for humans at all**.
Itâ€™s a **canonical, textual AST**: compact, deterministic, and trivial for an LLM to generate or read.

The goal:

* **LLM-friendly** â†’ minimal token footprint, no ambiguous syntax.
* **Compiler-friendly** â†’ direct parse into a typed IR, single-pass semantics.
* **Deterministic** â†’ unique canonical form; no stylistic variance.
* **Executable** â†’ compiles to bytecode, LLVM, or WASM; used for real computation.

---

## ðŸ“¡ Streaming to Clients

Workers emit raw text or NDJSON on stdout. An orchestrator reads NDJSON lines and re-emits Server-Sent Events (SSE) to browsers.

* Minimal SSE frame (one token):

  ```
  event: token
  data:<json>

  ```

* Cancellation: client closes the SSE stream; server cancels the task and ensures the child process is terminated within a deadline.

Framing modes:

* Inputs: `raw | ndjson` from `proc.stdout`.
* Outputs: `sse` (browser), `ws` (future profile).

---

## ðŸ“Œ Status

This monorepo contains both the evolving specification and a Rust reference implementation organized as a cargo workspace. Most crates are compiling stubs that are being wired end-to-end via the CLI for rapid iteration.

Current state:

* Parsing, AST, canonical formatting: `llmir-reader`, `llmir-ast`, `llmir-canon` (stubs, compiling)
* Schema + typing scaffolding: `llmir-schema`, `llmir-types` (stubs)
* Lowering + VM: `llmir-lower`, `llmir-vm` (skeletal bytecode + interpreter)
* Diagnostics + capabilities: `llmir-diag`, `llmir-sys` (shared primitives, null impls)
* Async profile traits: `llmir-asyncx` (API traits only)
* CLI + integration tests: `llmirc` (CLI binary), `llm-ir` (workspace-level tests)

Docs to read first:

* `docs/spec-surface.md` â€” grammar, node inventory, canonicalization, diagnostics
* `docs/features.md` â€” feature overview and scope
* `docs/conformance-pack.md` â€” end-to-end conformance scenarios
* `docs/CHEATSHEET.md` â€” quick reference for tags and shapes

Contributions are welcome across spec, examples, and conformance.

## ðŸ§° Workspace Crates

* `llmir-ast` â€” Core data types for the abstract syntax tree (AST); serde-friendly.
* `llmir-reader` â€” Parser from zero-indent s-expressions to `llmir-ast::Node`.
* `llmir-canon` â€” Canonical formatter/printer producing deterministic textual form.
* `llmir-diag` â€” Shared diagnostics primitives and error codes.
* `llmir-schema` â€” Table-driven arity/shape checks for core tags.
* `llmir-types` â€” Type system scaffold, including `res<T>` (Rails) signatures.
* `llmir-lower` â€” Lowers validated AST into a tiny bytecode for the VM.
* `llmir-vm` â€” Minimal reference interpreter for the bytecode.
* `llmir-sys` â€” Host capability traits (fs, proc, env, time, json, hash, http, gpu) with null impls.
* `llmir-asyncx` â€” Async profile traits (tasks, chans, timers, select).
* `llmirc` â€” CLI for `parse | canon | check | run` over `.llmir`/`.pulse` sources.
* `llm-ir` â€” Workspace-level integration tests spanning crates.

---

## ðŸŽ¯ Target Use-Case

LLM-IR is motivated by a Home Chatbot Service with an optional Agentic Mode:

* Small LLM emits a full service in one shot: tasks, process supervision, GPU pinning, bounded queues, cancellation, structured logs.
* Deterministic, token-cheap IR ensures repeatable builds and easy diffing.
* Profiles add capabilities as needed: async scheduling, OS/process control, GPU affinity, filesystem, hashing, timers, networking.

This shapes LLM-IR to be predictable for tools and learnable for small models.

---

## âœ¨ Features

* **Canonical S-expression format**: one space, one newline rule, no trivia comments. Use first-class `(c ...)` nodes for docs.
* **Minimal node set**: `mod, fn, type, struct, sum, let, call, if, match, â€¦`.
* **Primitive types**: `i32, i64, f64, bool, str, unit`.
* **Nominal types**: `struct`, `sum`, `alias`.
* **First-class functions**: lambdas, explicit signatures.
* **Control flow**: `if`, `while`, `for`, `match` with exhaustive patterns.
* **Errors (primary)**: Rails error-as-values (`ok/ef/es/eh/ec`) with `bind/map/orf/ors/fold/join`. No `try/catch` in Rails.
* **Arrays**: deterministic length, safe indexing, iteration protocol.
* **First-class docs/comments (core)**: `(c kind chan text [id] [(tags â€¦)])` attaches to the next node; compiler/runtime ignore, tools render; preserved by canonicalization.
* **Error rails (gated)**: enable with `(feat rails)` to use error-as-values (`ok/ef/es/eh/ec`) and combinators (`bind/map/orf/ors/fold/join`). Rails disables `throw/try/catch`.
* **Memory model**: ARC (automatic reference counting), deterministic release; no GC in MVP.
* **Hosted profile**: basic `io.print`, `math.*`, `arr.*`, classic `result<ok,err>` helpers. With Rails, prefer `res<T>` + combinators.
* **Deterministic semantics**: left-to-right eval, no unspecified order.

---

## ðŸ§  Memory Model (ARC, No GC)

* Immutable values by default; composites use **ARC** (automatic reference counting).
* Deterministic release at last reference drop; destructor timing is specified.
* Cycles unsupported in MVP (avoid by construction; weak refs may arrive in V1).

---

## ðŸ“¦ Project Layout

Workspace (selected):

```
llm-ir/
â”œâ”€ crates/
â”‚  â”œâ”€ ast/        # llmir-ast â€” core AST types
â”‚  â”œâ”€ reader/     # llmir-reader â€” parser
â”‚  â”œâ”€ canon/      # llmir-canon â€” canonical formatter
â”‚  â”œâ”€ schema/     # llmir-schema â€” shape checks
â”‚  â”œâ”€ types/      # llmir-types â€” type system scaffold
â”‚  â”œâ”€ lower/      # llmir-lower â€” lowers to bytecode
â”‚  â”œâ”€ vm/         # llmir-vm â€” reference VM
â”‚  â”œâ”€ sys/        # llmir-sys â€” host capability traits (Null* default)
â”‚  â”œâ”€ asyncx/     # llmir-asyncx â€” async profile traits
â”‚  â”œâ”€ diag/       # llmir-diag â€” diagnostics
â”‚  â”œâ”€ cli/        # llmirc â€” CLI binary
â”‚  â””â”€ llm-ir/     # integration test crate (workspace-level tests)
â”œâ”€ docs/
â”‚  â”œâ”€ spec-surface.md
â”‚  â”œâ”€ features.md
â”‚  â”œâ”€ CONFORMANCE.md
â”‚  â”œâ”€ conformance-pack.md
â”‚  â””â”€ CHEATSHEET.md
â”œâ”€ examples/
â”‚  â””â”€ agentic-home-orchestrator/ â€¦
â”œâ”€ Cargo.toml
â””â”€ README.md
```

---

## ðŸ› ï¸ Getting Started

Build the workspace and run tests:

```bash
cargo build
cargo test -q
```

Try the CLI (`llmirc`) end-to-end:

```bash
# show help
cargo run -p llmirc -- --help

# parse â†’ AST summary
cargo run -p llmirc -- parse examples/agentic-home-orchestrator/examples/quickstart.pulse

# canonicalize formatting
cargo run -p llmirc -- canon examples/agentic-home-orchestrator/examples/quickstart.pulse

# shape + type checks
cargo run -p llmirc -- check examples/agentic-home-orchestrator/examples/quickstart.pulse

# lower â†’ run in VM
cargo run -p llmirc -- run examples/agentic-home-orchestrator/examples/quickstart.pulse
```

Reading order for the spec:

1. `docs/spec-surface.md` â€” lexical/grammar surface, node inventory, canonicalization
2. `docs/features.md` â€” MVP scope and deferred features
3. `docs/conformance-pack.md` â€” executable-style scenarios and expectations

---

## ðŸ“š Modularity of Docs

Start here for a spec-first tour:

* `docs/features.md` â€” overview of MVP core, profiles (Rails, async, caps), and testing model.
* `docs/spec-surface.md` â€” grammar, node inventory, ARC memory, diagnostics, canonicalization.
* `docs/conformance-pack.md` â€” runnable-style scenarios grouped by theme.

Future module splits (to keep docs focused): `docs/async.md`, `docs/os.md`, `docs/errors.md`.

---

## ðŸ“– Example Program

Hello World in LLM-IR:

```
(mod main
(compact core)
(caps io)
(fn entry -> i32 ()
(io.print Hello)
0))
```

---

## ðŸ§ª Conformance Testing

The conformance surface is specified in `docs/conformance-pack.md`:

* **Positive tests** must parse, typecheck, run, and return expected value.
* **Negative tests** must fail with precise diagnostics (e.g., `E_PARSE`, `E_TYPE`).
* **Golden tests** define canonicalization round-trips (input â†’ canonical â†’ expected).
* **Differential tests** will compare VM vs backend traces for determinism.

---

## ðŸš§ Roadmap

* [ ] MVP spec draft (docs in this repo)
* [ ] Canonicalizer prototype
* [ ] Parser + AST validator
* [ ] Reference VM (single-threaded, ARC)
* [ ] Core test suite (â‰ˆ40 cases â†’ grow to 100+)
* [ ] Profiles: `(feat rails)` (primary errors), `(feat async)` (tasks/chan/timers/select), `(caps ...)`
* [ ] OS/Proc/GPU primitives: `proc.spawn/kill/wait`, stdio streams, GPU list/mask/affinity
* [ ] Deterministic testing hooks: fake clocks, golden logs, sandbox FS
* [ ] LLVM / WASM backend
* [ ] V1 features: generics, FFI, options, macros/CTE

---

## ðŸ¤ Contributing

This is a spec-first project. Please:

* Keep examples and scenarios in canonical form (see `docs/spec-surface.md`).
* When proposing new nodes or behavior, add/update the relevant section(s) and conformance scenarios.
* No feature without a spec section + at least one test scenario in `docs/conformance-pack.md`.

---

## ðŸ“œ License

MIT (spec and tools free to use, modify, and experiment with).

---

## ðŸ”­ Future Modules

Planned documentation splits to keep scope modular:

* `docs/async.md` â€” async runtime, tasks, channels, timers, select, scheduling.
* `docs/os.md` â€” processes, stdio streams, filesystem, hashing, GPU.
* `docs/errors.md` â€” Rails semantics, diagnostics, patterns, migration from classic `result`.

---

## ðŸ” End-to-End Streaming Example (sketch)

Zero-indent, token-cheap sketch showing headers and flow:

```
(mod srv
(rails)
(compact core)
(async)
(caps fs proc http json time gpu)
(com doc human "Stream llama.cpp NDJSON to SSE")
(fn route -> res<i32> ()
(let s (sse.open "/chat/stream"))
(let p (proc.spawn "/usr/bin/llama.cpp" (v "--json" "-p" "Hi") (v) "."))
(let out (proc.stdout p))
(let t (timer.after 60000))
select
(on_tick t (lam _ (orsoft (soft "timeout") 0)))
(on_recv out (lam line (pipe line (map _ (lam x (sse.send s x))) ok 0)))
(on_deadline (deadline.ms 30000) (lam _ (orsoft (soft "canceled") 0))))
))
```

Notes:

* Orchestrator reads NDJSON lines from `out`, converts each to an SSE `token` frame via `sse.send`, closes on cancel.

```
